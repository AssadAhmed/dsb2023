---
title: "Homerwork 1"
author: "Assad Ahmed"
date: 2023-05-14
format: 
  docx: default
  html:
    toc: true
    toc_float: true
    code-fold: true
editor: visual
---

```{r}
#| label: load-libraries
#| echo: false # This option disables the printing of code (only output is displayed).
#| message: false
#| warning: false

library(tidyverse)
library(nycflights13)
library(skimr)

#testing for changes in git tabgit add

```

# Data Manipulation

## Problem 1: Use logical operators to find flights that:

```         
-   Had an arrival delay of two or more hours (\> 120 minutes)
-   Flew to Houston (IAH or HOU)
-   Were operated by United (`UA`), American (`AA`), or Delta (`DL`)
-   Departed in summer (July, August, and September)
-   Arrived more than two hours late, but didn't leave late
-   Were delayed by at least an hour, but made up over 30 minutes in flight
```

glimpse(flights)

```{r}
#| label: problem-1
#Glimpse data set to view clumn names easily
dplyr::glimpse(flights)
#Utilising the table flights from the nycflights 13 library

# Had an arrival delay of two or more hours (> 120 minutes)
  #Create new dataframe to filter delays >=120mins
arr_delay_120mins <- flights %>% 
  #fliter for delays on arrival greater than or equal to 120 mins
  filter(arr_delay>=120)
#View new data frame top entries

head(arr_delay_120mins)

# Flew to Houston (IAH or HOU)
# create new data frame for the subset of arrivals into IAH and HOU
IAH_HOU <- flights %>% 
  filter(dest == "IAH" | dest== "HOU")
#view new data frame
head(IAH_HOU)

# Were operated by United (`UA`), American (`AA`), or Delta (`DL`)
#New data frame for the fights operated by the 3 airlines
UA_AA_DL <- flights %>% 
  filter(carrier == "UA" | carrier== "AA"| Carrier== "DL")
#view new data frame
head(UA_AA_DL)

# Departed in summer (July, August, and September)
# July, August, September are months 7-9 only  
#Define new data frame for summer flights
Summer <- flights %>% 
  filter(month  %in% c(7,8,9))
#view new data frame
head(Summer)

# Arrived more than two hours late, but didn't leave late
left_ontime_ari_late <- flights %>%
  filter(arr_delay>=120 & dep_delay<=0)
#view new data frame
head(left_ontime_ari_late)

# Were delayed by at least an hour, but made up over 30 minutes in flight
madeup_30min_delay <- flights %>%
  filter(dep_delay>=60 & (arr_delay-dep_delay)<=-30)%>%
  mutate(arr_minus_dep_delays =arr_delay-dep_delay)
#view new data frame
head(madeup_30min_delay)

```

```         
```

## Problem 2: What months had the highest and lowest proportion of cancelled flights? Interpret any seasonal patterns. To determine if a flight was cancelled use the following code

<!-- -->

```         
flights %>% 
  filter(is.na(dep_time)) 
  
view(flights)
```

```{r}
#| label: problem-2

# What months had the highest and lowest % of cancelled flights?

flights %>% 
  #Group by month
  group_by(month) %>% 
  #proportion of cancelled flights calculated by converting dep_time to True/false
  # Taking the total true values and dividng by the lenght of the created vector
  summarise(prop_Cancelled = sum(is.na(dep_time)) / length(dep_time),
            NumberofFLights = length(dep_time))



```

[**Interpreting the data:**]{.underline}

From the above summarized data we can see that between months 8-11 (assumed August-November) there are the lowest proportions of cancellations. Month 2 (February) has the larges proportion of cancellations (\~5%), closely followed by Months 12/6 at ( 3.6% each). This implies that over the busy holiday periods in June/December cancellations are more likely. February appears to be an outlier in terms of seasonality, with potentially the weather conditions in that month leading towards the increased cancellations.

## Problem 3: What plane (specified by the `tailnum` variable) traveled the most times from New York City airports in 2013? Please `left_join()` the resulting table with the table `planes` (also included in the `nycflights13` package).

For the plane with the greatest number of flights and that had more than 50 seats, please create a table where it flew to during 2013.

```{r}
#Glimpse the tables to identify concurrent columns and datatypes
dplyr::glimpse(flights)
dplyr::glimpse(planes)
#Talinumber is chr type in both tables, implies direct join possible
flights_2013 <-flights %>% 
  #Filter for 2013 only, and remove cancelled flights as the plane did not leave in those instances
  filter( year == 2013 & !is.na(dep_time)) %>% 
  #Group by plane ID
  group_by(tailnum) %>% 
  #count number of flights by tailnumbers
  summarise(count = n()) %>% 
  #Order largest to smallest number of flights
  arrange(desc(count))
#view tail numbers for the most active planes
head(flights_2013)
#N725MQ made the most flights

#Finding plane with the most flights in 2015 with more than 50 seats
#Joining the flights and planes tables
Flights_Planes <-left_join(x = flights, y = planes, by = "tailnum")
#viewing to ensure columns added
head(Flights_Planes)
#Creating a join table to flights_2013
Flights_Planes_2013 <-left_join(x = flights_2013, y = planes, by = "tailnum")
#viewing to ensure columns added
head(Flights_Planes)
#Finding plane with most number of flights in 2013 and more than 50 seats

#Finding the plane with >50 seats
#utiliseb the sorted and filtered dataframe created perviously
Seats_50 <- Flights_Planes_2013 %>% 
  #Filter for planes with >50 seats
  filter(seats >50 & !is.na(seats)) 
#view tail numbers for the most active planes with >50 seats
Head(Seats_50)
#we know that plane:N328AA was the most active with mroe than 50 seats
#Create a table of all 2013 flights by N328AA

Flights_Planes %>% 
  #filter for 2013 and N328AAflights only, also excluding cancelled flights
  filter(tailnum =="N328AA" & year.x == 2013 & !is.na(dep_time))

#Table shows the 389 lfights in 2013 as expected
```

## Problem 4: The `nycflights13` package includes a table (`weather`) that describes the weather during 2013. Use that table to answer the following questions:

```         
-   What is the distribution of temperature (`temp`) in July 2013? Identify any important outliers in terms of the `wind_speed` variable.
-   What is the relationship between `dewp` and `humid`?
-   What is the relationship between `precip` and `visib`?
```

```{r}
#Glipmse weather data set to view colums and data types
dplyr::glimpse(weather)

#View distribution of temp
skimr::skim(weather)
#Utilise the skim output to identify distribution of temps
#Mean temerature= 55.3 degrees with standard deviation of 17.78 degrees

#Identifying outliers in wind_speed
#Skim output shows clear outliers are present based on p100 being>>>2SD from mean

weather %>%
  #Remove any rows with NA windspeed
  filter (!is.na(wind_speed)) %>% 
  #Filter for wind speed values +/- 2 SD from mean Wind_Speed
  #Assuming a normal distribution
  filter(wind_speed <= (mean(wind_speed) - 2*sd(wind_speed))| wind_speed >= (mean(wind_speed) + 2*sd(wind_speed))) %>% 
  #arrange largest to smallest
  arrange(desc(wind_speed))

#the above shoes the windspeeds >2SD from the mean in the data which we can conclude as outliers.

#Identifying relationship between dewp and humid
#Utilise a plot to see clearly the relationship
ggplot(weather,aes(x=dewp,y=humid))+
  geom_point()

#lets confirm by calculating correlation between the 2 variables
weather %>% 
  #Remove NA's
  filter(!is.na(dewp) & !is.na(humid)) %>% 
  #Calculate correlation
  summarize(correlation=cor(dewp,humid))

#Correlation of 0.5 confirms the obervation above

#psotive correlation between dewp and humidity visible from chart, as humid increases, so does dewp

#Identifying relationship between precip and visib
#Utilise a plot to see clearly the relationship
ggplot(weather,aes(x=precip,y=visib))+
  geom_point()

#unclear from the above
weather %>% 
  group_by(month) %>% 
  ggplot(aes(x=precip,y=visib))+
  facet_wrap(~month, scales = "free")+
  geom_point()

#appears to be a varying relationship by month
#Calculate correlation by month

weather %>% 
  #Remove NA's
  filter(!is.na(dewp) & !is.na(humid)) %>% 
  #group_by month
  group_by(month) %>% 
  #Calculate correlation
  summarize(correlation=cor(dewp,humid))

#Dewp and humid appear to be positvely correlated, with the strength of this correlaiton varying by month

```

## Problem 5: Use the `flights` and `planes` tables to answer the following questions:

```         
-   How many planes have a missing date of manufacture?
-   What are the five most common manufacturers?
-   Has the distribution of manufacturer changed over time as reflected by the airplanes flying from NYC in 2013? (Hint: you may need to use case_when() to recode the manufacturer name and collapse rare vendors into a category called Other.)
```

```{r}
#Planes with missing date of manafacture
#join the planes and flights table
Flights_Planes <-left_join(x = flights, y = planes, by = "tailnum")
#Glimpse the planes table 
dplyr::glimpse(planes)
#View planes table
#view(planes)
#Missing date of manafacture from planes table
planes %>% 
  #Filter for entries with no manafacturer
  #assuming year is the year of manafacture
  filter(is.na(year)) %>% 
  #Count the number of planes with no manafacturer
  summarise(count =n())

# 70 planes have no date of manafacture

#Fnding the most common manafacturers

Pop_Man <- planes %>% 
  #Group by manafacturer
  group_by(manufacturer) %>% 
  #Count the number of planes for each manafacturer
  summarise(Count = n()) %>% 
  #Order most to least
  arrange(desc(Count))
#selecting the top 5
head(Pop_Man,5)
view(Pop_Man)

#Manafacturer distribition over time
#collapsing manafacturers with <100 planes into other catagory
#assmining the 2 similarly named MCDONNELL manafacturers
#Define list of manafactures to keep seperate
M <- c('BOEING', 'AIRBUS INDUSTRIE', 'BOMBARDIER INC', 'AIRBUS', 'EMBRAER','MCDONNELL DOUGLAS','MCDONNELL DOUGLAS AIRCRAFT CO')

simplified_mana <-planes %>% 
  #replace small manafacturer names with other
  mutate(manufacturer= case_when(manufacturer %in% M  ~ manufacturer, TRUE ~ 'Other'))
  mutate(count=n())
#plot manafacturer count over time

simplified_mana %>% 
  #Group by manafacturer
  group_by(manufacturer,year) %>% 
  #plot charts
  ggplot(aes(x=manufacturer))+
  facet_wrap(~year, scales = "free")+
  geom_bar()

# the plots showcase how much the manafacturer split has changed over time, with significant differences vibile year to year in recent times.
#This may be due to the manafacturing/lifespan cycles being longdated, with certain manafactures producing more inventory in some years Vs others.
```

## Problem 6: Use the `flights` and `planes` tables to answer the following questions:

```         
-   What is the oldest plane (specified by the tailnum variable) that flew from New York City airports in 2013?
-   How many airplanes that flew from New York City are included in the planes table?
```

```{r}
#join the planes and flights table
Flights_Planes <-left_join(x = flights, y = planes, by = "tailnum")

#oldest plane to fly from NY
oldest <- Flights_Planes %>% 
  #filter for 2013
  filter(year.x== 2013 & !is.na(year.y)) %>% 
  #Sort max to min on year/y
  arrange(year.y)
#View thetop 5 entries
head(oldest)
#oldest plane is N381AA

#Planes that flew from NY that are in the planes table, implies tailnumbers that are in both tables.
#manafacturer field is fully populated in lanes, implies use for count basis

Flights_Planes %>%
  #select manafacturecolumn from thejoined table
  select(manufacturer,tailnum) %>% 
  #filter out NA values
  filter(!is.na(manufacturer)) %>% 
  #Count distinct entries in the right join
  summarise(count= n_distinct(tailnum))

#implies 3322 planes from the planes table flew from NYC
```

## Problem 7: Use the `nycflights13` to answer the following questions:

```         
-   What is the median arrival delay on a month-by-month basis in each airport?
-   For each airline, plot the median arrival delay for each month and origin airport.
```

```{r}
#glimpse(flights)
#median arrival delay by airport
# arrival delay & origin airport assumed as variables from questions
#assumed month by month basis means across the same month in all years.

medians <- flights %>% 
  #Groupby airport & month
  group_by(origin,month) %>% 
  #Filter out NA's in the arr_delay field
  filter(!is.na(arr_delay)) %>% 
  #summarize to calculate the median for each month
  summarise(median= median(arr_delay)) %>% 
  #order by airport and by month
  arrange(origin,month)
  #plot charts

view(medians)
#plot charts by origin, dot plot
ggplot(medians, aes(x=month,y=median))+
  facet_wrap(~origin, scales = "free")+
  geom_point()
```

## Problem 8: Let's take a closer look at what carriers service the route to San Francisco International (SFO). Join the `flights` and `airlines` tables and count which airlines flew the most to SFO. Produce a new dataframe, `fly_into_sfo` that contains three variables: the `name` of the airline, e.g., `United Air Lines Inc.` not `UA`, the count (number) of times it flew to SFO, and the `percent` of the trips that that particular airline flew to SFO.

```{r}
#glimpse airlines table
#identify the join column
glimpse(airlines)
glimpse(flights)

#join the 2 tables
fly_into_sfo <- left_join(x=flights,y=airlines, by = "carrier") %>% 
  #add column that =1 if dest=SFO, 0 otherwise
  mutate(Fly_SFO = case_when(dest == 'SFO'  ~ 1, TRUE ~ 0)) %>% 
  #Group by airline name
  group_by(name) %>% 
  #Summarize to find the count of SFO and % to SFO for each airline name
  summarise(count= sum(Fly_SFO),
            percent = sum(Fly_SFO)/length(Fly_SFO))
#view table
view(fly_into_sfo)
```

And here is some bonus ggplot code to plot your dataframe

```{r}
#| label: ggplot-flights-toSFO
#| message: false
#| warning: false

fly_into_sfo %>% 
  
  # sort 'name' of airline by the numbers it times to flew to SFO
  mutate(name = fct_reorder(name, count)) %>% 
  
  ggplot() +
  
  aes(x = count, 
      y = name) +
  
  # a simple bar/column plot
  geom_col() +
  
  # add labels, so each bar shows the % of total flights 
  geom_text(aes(label = percent),
             hjust = 1, 
             colour = "white", 
             size = 5)+
  
  # add labels to help our audience  
  labs(title="Which airline dominates the NYC to SFO route?", 
       subtitle = "as % of total flights in 2013",
       x= "Number of flights",
       y= NULL) +
  
  theme_minimal() + 
  
  # change the theme-- i just googled those , but you can use the ggThemeAssist add-in
  # https://cran.r-project.org/web/packages/ggThemeAssist/index.html
  
  theme(#
    # so title is left-aligned
    plot.title.position = "plot",
    
    # text in axes appears larger        
    axis.text = element_text(size=12),
    
    # title text is bigger
    plot.title = element_text(size=18)
      ) +

  # add one final layer of NULL, so if you comment out any lines
  # you never end up with a hanging `+` that awaits another ggplot layer
  NULL
 
 
```

## Problem 9: Let's take a look at cancellations of flights to SFO. We create a new dataframe `cancellations` as follows

```{r}

cancellations <- flights %>% 
  
  # just filter for destination == 'SFO'
  filter(dest == 'SFO') %>% 
  
  # a cancelled flight is one with no `dep_time` 
  filter(is.na(dep_time))

```

I want you to think how we would organise our data manipulation to create the following plot. No need to write the code, just explain in words how you would go about it.

-   Step 1: group data by airport, origin, carrier, and ,month.

-   Step2: filter for any NA's across any of the above fields. Filter for WER& JFK airports only.Filter out for any airlines with a count =0 so that only the airlines with cancellations in SFO populate (avoid blank graphs)

-   Step 3: plot using a ggplot 2 and geom_bar() bar chart to show counts, and utilize facet wrap by carrier and origin to populate the charts as below

![](images/sfo-cancellations.png)

## Problem 10: On your own -- Hollywood Age Gap

The website https://hollywoodagegap.com is a record of *THE AGE DIFFERENCE IN YEARS BETWEEN MOVIE LOVE INTERESTS*. This is an informational site showing the age gap between movie love interests and the data follows certain rules:

-   The two (or more) actors play actual love interests (not just friends, coworkers, or some other non-romantic type of relationship)
-   The youngest of the two actors is at least 17 years old
-   No animated characters

The age gaps dataset includes "gender" columns, which always contain the values "man" or "woman". These values appear to indicate how the characters in each film identify and some of these values do not match how the actor identifies. We apologize if any characters are misgendered in the data!

The following is a data dictionary of the variables used

| variable            | class     | description                                                                                             |
|:----------------|:----------------|:-------------------------------------|
| movie_name          | character | Name of the film                                                                                        |
| release_year        | integer   | Release year                                                                                            |
| director            | character | Director of the film                                                                                    |
| age_difference      | integer   | Age difference between the characters in whole years                                                    |
| couple_number       | integer   | An identifier for the couple in case multiple couples are listed for this film                          |
| actor_1\_name       | character | The name of the older actor in this couple                                                              |
| actor_2\_name       | character | The name of the younger actor in this couple                                                            |
| character_1\_gender | character | The gender of the older character, as identified by the person who submitted the data for this couple   |
| character_2\_gender | character | The gender of the younger character, as identified by the person who submitted the data for this couple |
| actor_1\_birthdate  | date      | The birthdate of the older member of the couple                                                         |
| actor_2\_birthdate  | date      | The birthdate of the younger member of the couple                                                       |
| actor_1\_age        | integer   | The age of the older actor when the film was released                                                   |
| actor_2\_age        | integer   | The age of the younger actor when the film was released                                                 |

```{r}

age_gaps <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-02-14/age_gaps.csv')

library(usethis)
use_git_config(
user.name = "AssadAhmed",
user.email = "assad139@gmail.com"
)

usethis::create_github_token()
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
```

How would you explore this data set? Here are some ideas of tables/ graphs to help you with your analysis

-   How is `age_difference` distributed? What's the 'typical' `age_difference` in movies?

-   The `half plus seven\` rule. Large age disparities in relationships carry certain stigmas. One popular rule of thumb is the [half-your-age-plus-seven](https://en.wikipedia.org/wiki/Age_disparity_in_sexual_relationships#The_.22half-your-age-plus-seven.22_rule) rule. This rule states you should never date anyone under half your age plus seven, establishing a minimum boundary on whom one can date. In order for a dating relationship to be acceptable under this rule, your partner's age must be:

$$\frac{\text{Your age}}{2} + 7 < \text{Partner Age} < (\text{Your age} - 7) * 2$$ How frequently does this rule apply in this dataset?

-   Which movie has the greatest number of love interests?
-   Which actors/ actresses have the greatest number of love interests in this dataset?
-   Is the mean/median age difference staying constant over the years (1935 - 2022)?
-   How frequently does Hollywood depict same-gender love interests?

# Deliverables

There is a lot of explanatory text, comments, etc. You do not need these, so delete them and produce a stand-alone document that you could share with someone. Render the edited and completed Quarto Markdown (qmd) file as a Word document (use the "Render" button at the top of the script editor window) and upload it to Canvas. You must be commiting and pushing tour changes to your own Github repo as you go along.

# Details

-   Who did you collaborate with: NA
-   Approximately how much time did you spend on this problem set: 3 hours
-   What, if anything, gave you the most trouble: ANSWER HERE

**Please seek out help when you need it,** and remember the [15-minute rule](https://mam2022.netlify.app/syllabus/#the-15-minute-rule){target="_blank"}. You know enough R (and have enough examples of code from class and your readings) to be able to do this. If you get stuck, ask for help from others, post a question on Slack-- and remember that I am here to help too!

> As a true test to yourself, do you understand the code you submitted and are you able to explain it to someone else?

# Rubric

13/13: Problem set is 100% completed. Every question was attempted and answered, and most answers are correct. Code is well-documented (both self-documented and with additional comments as necessary). Used tidyverse, instead of base R. Graphs and tables are properly labelled. Analysis is clear and easy to follow, either because graphs are labeled clearly or you've written additional text to describe how you interpret the output. Multiple Github commits. Work is exceptional. I will not assign these often.

8/13: Problem set is 60--80% complete and most answers are correct. This is the expected level of performance. Solid effort. Hits all the elements. No clear mistakes. Easy to follow (both the code and the output). A few Github commits.

5/13: Problem set is less than 60% complete and/or most answers are incorrect. This indicates that you need to improve next time. I will hopefully not assign these often. Displays minimal effort. Doesn't complete all components. Code is poorly written and not documented. Uses the same type of plot for each graph, or doesn't use plots appropriate for the variables being analyzed. No Github commits.
